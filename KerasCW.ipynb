{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "strategy = tf.distribute.TPUStrategy(tpu)"
      ],
      "metadata": {
        "id": "LEzMWZZBJ87r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03IE7BbAoowF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bd9c277-8278-46ca-c82b-998ecc46efd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(x_train, labels_train), (x_test, labels_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "metadata": {
        "id": "eKvo4YekqSPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(labels_train, 10)\n",
        "y_test = to_categorical(labels_test, 10)"
      ],
      "metadata": {
        "id": "s7FlDwPgqT8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
      ],
      "metadata": {
        "id": "rt7tT4cdqVf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, Input\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.models import Sequential\n",
        "model = Sequential([\n",
        "    layers.Input(shape=(28, 28, 1)),\n",
        "    Conv2D(32, kernel_size=3, activation=\"relu\", input_shape=(28, 28, 1)),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(32, kernel_size=3, activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(32, kernel_size=5, activation=\"relu\", strides=2, padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "    \n",
        "    Conv2D(32, kernel_size=3, activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(32, kernel_size=3, activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(64, kernel_size=5, activation=\"relu\", strides=2, padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "    Conv2D(64, kernel_size=5, activation=\"relu\", strides=2, padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "    Conv2D(64, kernel_size=5, activation=\"relu\", strides=2, padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "    Conv2D(64, kernel_size=5, activation=\"relu\", strides=2, padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "    Conv2D(64, kernel_size=5, activation=\"relu\", strides=2, padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "    Conv2D(128, kernel_size=5, activation=\"relu\", strides=2, padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "    Conv2D(128, kernel_size=5, activation=\"relu\", strides=2, padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "    Flatten(),\n",
        "    Dense(256, activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "    Dense(10, activation=\"softmax\"),\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "mi32aFOHpnFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate new data\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "# specify the arguments\n",
        "rotation_range_val = 10\n",
        "width_shift_val = 0.1\n",
        "height_shift_val = 0.1\n",
        "shear_range_val= 10\n",
        "zoom_range_val=0.1\n",
        "\n",
        "# import relevant library\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# create the class object\n",
        "datagen = ImageDataGenerator(rotation_range = rotation_range_val,\n",
        "                             width_shift_range = width_shift_val,\n",
        "                             height_shift_range = height_shift_val,\n",
        "                             zoom_range=zoom_range_val)\n",
        "\n",
        "# fit the generator\n",
        "datagen.fit(x_test.reshape(x_test.shape[0], 28, 28, 1))\n",
        "\n",
        "# Total number of test data\n",
        "num = 40000\n",
        "\n",
        "# Generate new augmented data\n",
        "for new_x_test, y in datagen.flow(x_test.reshape(x_test.shape[0], 28, 28, 1),labels_test.reshape(labels_test.shape[0], 1),batch_size=num,shuffle=False):\n",
        "    break\n",
        "    \n",
        "new_labels_test = y.flatten()\n",
        "lr_schedule = LearningRateScheduler(lambda epoch: 1e-3 * (0.95**epoch))"
      ],
      "metadata": {
        "id": "zmhnPmSVq6MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
        "history = model.fit(x_train, y_train,validation_data=(x_test, y_test),callbacks=[lr_schedule],epochs=20,batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vcZaNBYq-yl",
        "outputId": "3aea7bc6-c04a-4788-9121-7291a2c1dd17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 359s 753ms/step - loss: 1.6916 - accuracy: 0.4032 - val_loss: 2.9585 - val_accuracy: 0.2735 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 329s 703ms/step - loss: 0.5338 - accuracy: 0.8276 - val_loss: 0.1249 - val_accuracy: 0.9698 - lr: 9.5000e-04\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 335s 714ms/step - loss: 0.2351 - accuracy: 0.9423 - val_loss: 0.0759 - val_accuracy: 0.9834 - lr: 9.0250e-04\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 331s 707ms/step - loss: 0.1679 - accuracy: 0.9612 - val_loss: 0.0714 - val_accuracy: 0.9855 - lr: 8.5737e-04\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 334s 712ms/step - loss: 0.1334 - accuracy: 0.9697 - val_loss: 0.0558 - val_accuracy: 0.9880 - lr: 8.1451e-04\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 328s 700ms/step - loss: 0.1235 - accuracy: 0.9728 - val_loss: 0.0635 - val_accuracy: 0.9873 - lr: 7.7378e-04\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 331s 705ms/step - loss: 0.1124 - accuracy: 0.9766 - val_loss: 0.0498 - val_accuracy: 0.9891 - lr: 7.3509e-04\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 332s 708ms/step - loss: 0.1017 - accuracy: 0.9781 - val_loss: 0.0421 - val_accuracy: 0.9909 - lr: 6.9834e-04\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 332s 707ms/step - loss: 0.0930 - accuracy: 0.9799 - val_loss: 0.0432 - val_accuracy: 0.9917 - lr: 6.6342e-04\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 320s 682ms/step - loss: 0.0877 - accuracy: 0.9812 - val_loss: 0.0623 - val_accuracy: 0.9881 - lr: 6.3025e-04\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 320s 682ms/step - loss: 0.0792 - accuracy: 0.9833 - val_loss: 0.0406 - val_accuracy: 0.9922 - lr: 5.9874e-04\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 321s 684ms/step - loss: 0.0768 - accuracy: 0.9837 - val_loss: 0.0371 - val_accuracy: 0.9933 - lr: 5.6880e-04\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 319s 681ms/step - loss: 0.0696 - accuracy: 0.9855 - val_loss: 0.0469 - val_accuracy: 0.9907 - lr: 5.4036e-04\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 321s 683ms/step - loss: 0.0712 - accuracy: 0.9853 - val_loss: 0.0372 - val_accuracy: 0.9921 - lr: 5.1334e-04\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 318s 678ms/step - loss: 0.0672 - accuracy: 0.9869 - val_loss: 0.0403 - val_accuracy: 0.9925 - lr: 4.8767e-04\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 320s 682ms/step - loss: 0.0596 - accuracy: 0.9878 - val_loss: 0.0331 - val_accuracy: 0.9941 - lr: 4.6329e-04\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 320s 683ms/step - loss: 0.0544 - accuracy: 0.9883 - val_loss: 0.0347 - val_accuracy: 0.9936 - lr: 4.4013e-04\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 320s 681ms/step - loss: 0.0530 - accuracy: 0.9894 - val_loss: 0.0323 - val_accuracy: 0.9946 - lr: 4.1812e-04\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 319s 681ms/step - loss: 0.0481 - accuracy: 0.9898 - val_loss: 0.0396 - val_accuracy: 0.9926 - lr: 3.9721e-04\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 321s 684ms/step - loss: 0.0457 - accuracy: 0.9905 - val_loss: 0.0248 - val_accuracy: 0.9955 - lr: 3.7735e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'], label='training loss')\n",
        "plt.plot(history.history['val_loss'], label='validation loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "W5wI0GLfpzC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "outputs=model.predict(x_test)\n",
        "labels_predicted=np.argmax(outputs, axis=1)\n",
        "misclassified=sum(labels_predicted!=labels_test)\n",
        "misclassified_percentage = print('Percentage misclassified = ',100*misclassified/labels_test.size)\n",
        "print('Accuracy = ',100-(100*misclassified/labels_test.size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3MuK08dTrPt",
        "outputId": "c5d0236a-db91-4204-e3af-5292491603d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 9s 13ms/step\n",
            "Percentage misclassified =  0.39\n",
            "Accuracy =  99.61\n"
          ]
        }
      ]
    }
  ]
}